{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "import circuit_lib as cl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "print(jax.devices())\n",
    "jax.config.update('jax_enable_x64', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"apple_quality_balanced_dataset.csv\", header = 0)\n",
    "\n",
    "df.loc[df[\"Quality\"] == \"good\", \"Quality\"] = 1\n",
    "df.loc[df[\"Quality\"] == \"bad\", \"Quality\"] = 0\n",
    "df = df.drop(columns=[\"A_id\"])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_x = scaler.fit_transform(df.iloc[:,:7])\n",
    "\n",
    "train = scaled_x[:850]\n",
    "test = scaled_x[850:]\n",
    "\n",
    "x_train = jnp.array(train)\n",
    "y_train = jnp.array(df.iloc[:850,7].to_numpy(dtype= np.float32))\n",
    "\n",
    "x_test = jnp.array(test)\n",
    "y_test = jnp.array(df.iloc[850:,7].to_numpy(dtype= np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires = 7)\n",
    "\n",
    "ZZFeatureMap = cl.create_ZZFeatureMap(dev)\n",
    "\n",
    "@qml.qnode(dev, interface=\"jax\")\n",
    "def EmbeddingCircuit(x):\n",
    "    ZZFeatureMap(x)\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def embeddor(x):\n",
    "    return EmbeddingCircuit(x)\n",
    "\n",
    "embedding_map = jax.vmap(embeddor,[0])\n",
    "\n",
    "x_train_embedding = embedding_map(x_train)\n",
    "x_test_embedding = embedding_map(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 6\n",
    "entanglement = cl.SCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "observable = qml.numpy.asarray([[0,0],\n",
    "                        [0,1]])\n",
    "\n",
    "observable = qml.numpy.array([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "TwoLocal = cl.create_TwoLocal(dev,num_reps,entanglement)\n",
    "@qml.qnode(dev, interface = \"jax\")\n",
    "def QuantumCircuit(params, embedding):\n",
    "    qml.StatePrep(embedding, wires = [0,1,2,3,4,5,6], normalize= True)\n",
    "    TwoLocal(params)\n",
    "    for i in range(7):\n",
    "        qml.Hadamard(i)\n",
    "    return qml.expval(qml.Hermitian(observable, wires=[0,1,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def mse(params, data, target):\n",
    "    return (target - QuantumCircuit(params, data))**2\n",
    "\n",
    "mse_map = jax.vmap(mse, (None, 0, 0))\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(params, data, target):\n",
    "    return jnp.mean(mse_map(params, data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_schedule = optax.schedules.join_schedules(schedules = [optax.constant_schedule((0.75)**i) for i in range(6)],\n",
    "                                                                     boundaries = [100, 250, 500, 700, 900])\n",
    "opt = optax.adam(1e20)\n",
    "max_steps = 1000\n",
    "@jax.jit\n",
    "def optimiser(params, data, targets, print_training):\n",
    "    param_history = jnp.zeros(((max_steps + 1),) + params.shape)  \n",
    "    grad_history = jnp.zeros(((max_steps + 1),) + params.shape)  \n",
    "    opt_state = opt.init(params)\n",
    "    #Packages the arguments to be sent to the function update_step_jit \n",
    "    args = (params, opt_state, jnp.asarray(data), targets, print_training, param_history, grad_history)\n",
    "    #Loops max_steps number of times\n",
    "    (params, opt_state, _, _, _, param_history, grad_history) = jax.lax.fori_loop(0, max_steps+1, update_step_jit, args) \n",
    "    return params, param_history, grad_history\n",
    "\n",
    "@jax.jit\n",
    "def update_step_jit(i,args):\n",
    "    # Unpacks the arguments\n",
    "    params, opt_state, data, targets, print_training, param_history, grad_history = args\n",
    "    param_history = param_history.at[i].set(params)\n",
    "    # Gets the loss and the gradients to be applied to the parameters, by passing in the loss function and the parameters, to see how the parameters perform \n",
    "    loss_val, grads = jax.value_and_grad(loss_fn)(params, data, targets)\n",
    "    grad_history = grad_history.at[i].set(grads)\n",
    "    #Prints the loss every 25 steps if print_training is enable\n",
    "    def print_fn():\n",
    "        jax.debug.print(\"Step: {i}  Loss: {loss_val}\", i=i, loss_val=loss_val)\n",
    "    jax.lax.cond((jnp.mod(i, 50) == 0 ) & print_training, print_fn, lambda: None)\n",
    "    #Applies the param updates and updates the optimiser states\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    #Returns the arguments to be resupplied in the next iteration\n",
    "    return (params, opt_state, data, targets, print_training, param_history, grad_history)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melon/my-projects/NU25/PennylaneAnalysis/env/lib/python3.12/site-packages/pennylane/math/interface_utils.py:127: UserWarning: Contains tensors of types {'autograd', 'jax'}; dispatch will prioritize TensorFlow, PyTorch, and Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0  Loss: 0.24242673928422356\n",
      "Step: 50  Loss: 0.24998667709954\n",
      "Step: 100  Loss: 0.25232226035008376\n",
      "Step: 150  Loss: 0.25170440099981073\n",
      "Step: 200  Loss: 0.24368691560392197\n",
      "Step: 250  Loss: 0.2562264973985301\n",
      "Step: 300  Loss: 0.2514164339285035\n",
      "Step: 350  Loss: 0.2547674236774299\n",
      "Step: 400  Loss: 0.250229512463104\n",
      "Step: 450  Loss: 0.2518204284793223\n",
      "Step: 500  Loss: 0.25601424784704446\n",
      "Step: 550  Loss: 0.2524158902377224\n",
      "Step: 600  Loss: 0.24671911549767178\n",
      "Step: 650  Loss: 0.24932116880618785\n",
      "Step: 700  Loss: 0.24393344715776835\n",
      "Step: 750  Loss: 0.24576811531342727\n",
      "Step: 800  Loss: 0.26021793320784764\n",
      "Step: 850  Loss: 0.26827953128418597\n",
      "Step: 900  Loss: 0.24937669030962323\n",
      "Step: 950  Loss: 0.25023331993601255\n",
      "Step: 1000  Loss: 0.25962754204111194\n",
      "0.25345422523992844\n"
     ]
    }
   ],
   "source": [
    "init_params = jnp.array(np.random.default_rng().random(size=(num_reps + 1, 7))\n",
    ")\n",
    "opt_params, params_hist, grad_hist = optimiser(init_params, x_train_embedding, y_train, True)\n",
    "print(loss_fn(opt_params, x_test_embedding, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83447189 0.73620322 0.94334843 0.69785405 0.42409798 0.3311938\n",
      "  0.11164608]\n",
      " [0.40849868 0.34635488 0.12168918 0.61002939 0.37040859 0.43267123\n",
      "  0.90275899]\n",
      " [0.32874892 0.78818826 0.16675669 0.85882916 0.68963156 0.49743242\n",
      "  0.18986433]\n",
      " [0.9298198  0.80092225 0.30607966 0.03111455 0.5737384  0.31792827\n",
      "  0.10503104]\n",
      " [0.67123105 0.58436243 0.45929824 0.85950728 0.33422571 0.05206273\n",
      "  0.91733703]\n",
      " [0.28639464 0.78547651 0.97777961 0.78469062 0.39450294 0.54850348\n",
      "  0.31256419]\n",
      " [0.04738927 0.1742703  0.76815272 0.5933384  0.12484139 0.7514961\n",
      "  0.36935942]]\n",
      "[[ 20.99953229   9.13853645  -0.84791714   8.31992197   6.11225803\n",
      "    7.98665302  22.35077907]\n",
      " [  3.44577929   2.06278934  18.68668613  20.92378007 -14.31052478\n",
      "    7.01024174   5.96652542]\n",
      " [ 28.70170463   6.34442725  20.68834095  22.59107106  26.5337786\n",
      "   46.434774     2.6596951 ]\n",
      " [ -1.4121484   38.74704012  32.08126515   6.11222427  18.2821172\n",
      "   33.53854054   9.91112895]\n",
      " [ -4.39534485   3.51724037  15.53165874  -2.30227011  -0.10750015\n",
      "   17.68125316   9.64693553]\n",
      " [ 17.72993756  15.56031861  -7.99133354  -2.36236354 -16.05762878\n",
      "    4.70666056 -14.09156789]\n",
      " [  0.04738927   3.94517142   4.01875676  16.90290071  -3.51448388\n",
      "   11.3928267  -20.17704557]]\n",
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(params_hist[0])\n",
    "print(params_hist[500])\n",
    "print(params_hist[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.33680869e-19  1.08420217e-18  6.50521303e-19 -1.95156391e-18\n",
      "  -3.25260652e-19  8.67361738e-19  0.00000000e+00]\n",
      " [ 1.73472348e-18  5.14996032e-19 -2.16840434e-19  8.67361738e-19\n",
      "   3.25260652e-19  2.71050543e-19  4.33680869e-19]\n",
      " [ 9.75781955e-19  1.08420217e-18 -4.33680869e-19  1.51788304e-18\n",
      "   8.67361738e-19 -2.16840434e-19  6.50521303e-19]\n",
      " [-6.50521303e-19  0.00000000e+00 -1.08420217e-18  1.73472348e-18\n",
      "   0.00000000e+00  1.51788304e-18  8.67361738e-19]\n",
      " [-4.33680869e-19 -4.33680869e-19  4.33680869e-19  6.50521303e-19\n",
      "   2.16840434e-18  6.50521303e-19  4.33680869e-19]\n",
      " [ 6.50521303e-19 -2.16840434e-19 -1.95156391e-18  4.33680869e-19\n",
      "   1.08420217e-18  4.33680869e-19 -2.16840434e-19]\n",
      " [ 0.00000000e+00  4.33680869e-19 -2.16840434e-19  1.08420217e-19\n",
      "   2.16840434e-19 -2.03287907e-19 -2.16840434e-19]]\n",
      "[[ 2.16840434e-19 -2.38524478e-18 -1.30104261e-18 -4.33680869e-19\n",
      "  -4.33680869e-19 -6.50521303e-19 -4.33680869e-19]\n",
      " [ 2.16840434e-19 -8.94466792e-19  2.16840434e-19 -2.16840434e-19\n",
      "  -2.16840434e-19 -1.13841228e-18 -1.30104261e-18]\n",
      " [-2.05998413e-18 -1.30104261e-18 -9.75781955e-19 -6.50521303e-19\n",
      "  -2.16840434e-18  0.00000000e+00 -8.67361738e-19]\n",
      " [-6.50521303e-19 -1.95156391e-18 -1.51788304e-18 -1.73472348e-18\n",
      "  -4.33680869e-19 -8.67361738e-19 -1.30104261e-18]\n",
      " [ 2.16840434e-19 -3.25260652e-19 -8.94466792e-19  0.00000000e+00\n",
      "  -2.16840434e-19  2.16840434e-19 -4.33680869e-19]\n",
      " [-2.16840434e-19  1.08420217e-18  0.00000000e+00 -2.16840434e-19\n",
      "   6.50521303e-19  6.50521303e-19  8.67361738e-19]\n",
      " [ 0.00000000e+00  4.33680869e-19  2.16840434e-19  6.50521303e-19\n",
      "  -1.08420217e-19 -1.82959117e-19 -1.08420217e-18]]\n"
     ]
    }
   ],
   "source": [
    "print(grad_hist[0])\n",
    "print(grad_hist[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
