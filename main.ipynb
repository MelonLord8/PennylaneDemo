{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "import circuit_lib as cl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "print(jax.devices())\n",
    "jax.config.update('jax_enable_x64', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"apple_quality_balanced_dataset.csv\", header = 0)\n",
    "\n",
    "df.loc[df[\"Quality\"] == \"good\", \"Quality\"] = 1\n",
    "df.loc[df[\"Quality\"] == \"bad\", \"Quality\"] = 0\n",
    "df = df.drop(columns=[\"A_id\"])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_x = scaler.fit_transform(df.iloc[:,:7])\n",
    "\n",
    "train = scaled_x[:850]\n",
    "test = scaled_x[850:]\n",
    "\n",
    "x_train = jnp.array(train)\n",
    "y_train = jnp.array(df.iloc[:850,7].to_numpy(dtype= np.float32))\n",
    "\n",
    "x_test = jnp.array(test)\n",
    "y_test = jnp.array(df.iloc[850:,7].to_numpy(dtype= np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires = 7)\n",
    "\n",
    "ZZFeatureMap = cl.create_ZZFeatureMap(dev)\n",
    "\n",
    "@qml.qnode(dev, interface=\"jax\")\n",
    "def EmbeddingCircuit(x):\n",
    "    ZZFeatureMap(x)\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def embeddor(x):\n",
    "    return EmbeddingCircuit(x)\n",
    "\n",
    "embedding_map = jax.vmap(embeddor,[0])\n",
    "\n",
    "x_train_embedding = embedding_map(x_train)\n",
    "x_test_embedding = embedding_map(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 6\n",
    "entanglement = cl.CIRCULAR   \n",
    "\n",
    "wires = dev.wires\n",
    "num_wires = len(wires)\n",
    "def entanglement_layer():\n",
    "    qml.CNOT(wires = [wires[num_wires - 1], wires[0]])\n",
    "    for i in range(num_wires - 1):\n",
    "        qml.CNOT(wires = [wires[i], wires[i+1]])\n",
    "\n",
    "def phase_rotation(params):\n",
    "    for i in range(num_wires):\n",
    "        qml.PhaseShift(params[i], wires[i])\n",
    "def TwoLocal(params):\n",
    "    phase_rotation(params[0])\n",
    "    for layer in range(1, num_reps + 1):\n",
    "        entanglement_layer()\n",
    "        phase_rotation(params[layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "observable = qml.numpy.asarray([[0,0],\n",
    "                        [0,1]])\n",
    "\n",
    "observable = qml.numpy.array([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "@qml.qnode(dev, interface = \"jax\")\n",
    "def QuantumCircuit(params, embedding):\n",
    "    qml.StatePrep(embedding, wires = [0,1,2,3,4,5,6], normalize= True)\n",
    "    TwoLocal(params)\n",
    "    return qml.expval(qml.Hermitian(observable, wires=[0,1,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def mse(params, data, target):\n",
    "    return (target - QuantumCircuit(params, data))**2\n",
    "\n",
    "mse_map = jax.vmap(mse, (None, 0, 0))\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(params, data, target):\n",
    "    return jnp.mean(mse_map(params, data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adam(0.1)\n",
    "max_steps = 500\n",
    "@jax.jit\n",
    "def optimiser(params, data, targets, print_training):\n",
    "    param_history = jnp.zeros(((max_steps + 1),) + params.shape)  \n",
    "    opt_state = opt.init(params)\n",
    "    #Packages the arguments to be sent to the function update_step_jit \n",
    "    args = (params, opt_state, jnp.asarray(data), targets, print_training, param_history)\n",
    "    #Loops max_steps number of times\n",
    "    (params, opt_state, _, _, _, param_history) = jax.lax.fori_loop(0, max_steps+1, update_step_jit, args) \n",
    "    return params, param_history\n",
    "\n",
    "@jax.jit\n",
    "def update_step_jit(i,args):\n",
    "    # Unpacks the arguments\n",
    "    params, opt_state, data, targets, print_training, param_history = args\n",
    "    param_history = param_history.at[i].set(params)\n",
    "    # Gets the loss and the gradients to be applied to the parameters, by passing in the loss function and the parameters, to see how the parameters perform \n",
    "    loss_val, grads = jax.value_and_grad(loss_fn)(params, data, targets)\n",
    "    #Prints the loss every 25 steps if print_training is enable\n",
    "    def print_fn():\n",
    "        jax.debug.print(\"Step: {i}  Loss: {loss_val} Gradient norm: {g}\", g= jnp.linalg.norm(grads), i=i, loss_val=loss_val)\n",
    "    jax.lax.cond((jnp.mod(i, 50) == 0 ) & print_training, print_fn, lambda: None)\n",
    "    #Applies the param updates and updates the optimiser states\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    #Returns the arguments to be resupplied in the next iteration\n",
    "    return (params, opt_state, data, targets, print_training, param_history)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0  Loss: 0.24999999999999997 Gradient norm: 8.245640863605515e-18\n",
      "Step: 50  Loss: 0.24999999999999997 Gradient norm: 7.21137088772849e-18\n",
      "Step: 100  Loss: 0.24999999999999997 Gradient norm: 7.224399572041235e-18\n",
      "Step: 150  Loss: 0.24999999999999997 Gradient norm: 6.86052430991425e-18\n",
      "Step: 200  Loss: 0.24999999999999997 Gradient norm: 5.642019764257083e-18\n",
      "Step: 250  Loss: 0.24999999999999997 Gradient norm: 7.126103841197012e-18\n",
      "Step: 300  Loss: 0.24999999999999997 Gradient norm: 6.573520543531243e-18\n",
      "Step: 350  Loss: 0.24999999999999997 Gradient norm: 7.61724367186636e-18\n",
      "Step: 400  Loss: 0.24999999999999997 Gradient norm: 6.1101309791293226e-18\n",
      "Step: 450  Loss: 0.24999999999999997 Gradient norm: 6.952433221959954e-18\n",
      "Step: 500  Loss: 0.24999999999999997 Gradient norm: 6.3033093734794044e-18\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "init_params = jnp.ones(shape=(num_reps + 1, 7)\n",
    ")\n",
    "opt_params, params_hist = optimiser(init_params, x_train_embedding, y_train, True)\n",
    "print(loss_fn(opt_params, x_test_embedding, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12520351 -0.33444239  0.62504313  0.26925998  0.19504671 -0.23168405\n",
      "  -0.56353509]\n",
      " [ 0.20597923 -0.017325   -0.31597895  0.4934467  -0.65271617 -0.3715017\n",
      "  -0.22335656]\n",
      " [ 0.1572723  -0.17718732 -0.2554929   0.17977453  0.01274453  0.80102742\n",
      "  -0.45218052]\n",
      " [ 0.08611685  0.06476738  0.08938308 -0.77294991 -0.41919139 -0.04938587\n",
      "  -0.45253485]\n",
      " [-0.34219927  0.23687799 -0.57380386 -0.05112175  0.451848   -0.30871563\n",
      "  -0.44209978]\n",
      " [-0.85646676 -0.31312522 -0.06690812 -0.00941428 -0.35953292  0.14855119\n",
      "   0.11189541]\n",
      " [ 0.24312609 -0.83552342 -0.32013258 -0.22701744  0.16310733 -0.21645392\n",
      "   0.12374261]]\n",
      "[[-0.12520351 -0.33444239  0.62504313  0.26925998  0.19504671 -0.23168405\n",
      "  -0.56353509]\n",
      " [ 0.20597923 -0.017325   -0.31597895  0.4934467  -0.65271617 -0.3715017\n",
      "  -0.22335656]\n",
      " [ 0.1572723  -0.17718732 -0.2554929   0.17977453  0.01274453  0.80102742\n",
      "  -0.45218052]\n",
      " [ 0.08611685  0.06476738  0.08938308 -0.77294991 -0.41919139 -0.04938587\n",
      "  -0.45253485]\n",
      " [-0.34219927  0.23687799 -0.57380386 -0.05112175  0.451848   -0.30871563\n",
      "  -0.44209978]\n",
      " [-0.85646676 -0.31312522 -0.06690812 -0.00941428 -0.35953292  0.14855119\n",
      "   0.11189541]\n",
      " [ 0.24312609 -0.83552342 -0.32013258 -0.22701744  0.16310733 -0.21645392\n",
      "   0.12374261]]\n",
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(params_hist[0])\n",
    "print(params_hist[100])\n",
    "print(params_hist[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
